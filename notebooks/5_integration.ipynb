{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cdf719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503f5277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\winon\\Documents\\Bootcamp\\ai-spam-call-detection\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qwen_asr import Qwen3ASRModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78280b2c",
   "metadata": {},
   "source": [
    "## Load ASR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6720583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "asr_model = Qwen3ASRModel.from_pretrained(\n",
    "    \"Qwen/Qwen3-ASR-0.6B\",\n",
    "    dtype=torch.float32,\n",
    "    device_map=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c624c16",
   "metadata": {},
   "source": [
    "## Transcribe Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addca5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    result = asr_model.transcribe(\n",
    "        audio=audio_path,\n",
    "        language=\"English\"\n",
    "    )\n",
    "\n",
    "    text = result[0].text\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bee8e",
   "metadata": {},
   "source": [
    "## Load TF-IDF + XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f090cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = joblib.load(\"tf-idf_xgb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293e8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xgb(text):\n",
    "    prob = xgb_model.predict_proba([text])[:, 1][0]\n",
    "    pred = 1 if prob > 0.5 else 0\n",
    "    return pred, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31128676",
   "metadata": {},
   "source": [
    "## Load GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b9d6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab loaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"models/gru_vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "print(\"Vocab loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0517b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True, dropout=0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, h = self.gru(x)\n",
    "        out = self.fc(h[-1])\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473cd8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\winon\\Documents\\Bootcamp\\ai-spam-call-detection\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1334: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  super().__init__(\"GRU\", *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRUModel(len(vocab), 128, 64)\n",
    "gru_model.load_state_dict(torch.load(\"models/gru_models.pth\"))\n",
    "gru_model.eval()\n",
    "\n",
    "print(\"GRU loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a7dcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "def encode(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize(text)\n",
    "    ids = [vocab.get(t, 1) for t in tokens]\n",
    "    return ids[:MAX_LEN]\n",
    "\n",
    "def pad(seq):\n",
    "    return seq + [0] * (MAX_LEN - len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9972b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gru(text, threshold=0.4):\n",
    "    ids = pad(encode(text))\n",
    "    tensor_input = torch.tensor([ids])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = gru_model(tensor_input)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        prob = probs.item()\n",
    "        pred = 1 if prob > threshold else 0\n",
    "\n",
    "    return pred, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c6992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: Hello, I am an artificial intelligent notification bot. The purpose of this call is to make you aware that as a U.S. resident, you are now able to take advantage of alternative federal student loan repayment options and hardship programs. These programs are only for individuals who have less than one hundred and sixty thousand dollars in federal student loan debt. Having debt obligations may cause a hardship when added to your overall monthly bills. Using our automated approval technology, you are now able to obtain enrollment information based on your current situation.\n",
      "\n",
      "=== RESULT ===\n",
      "XGB = Pred: 1 Prob: 0.9945802\n",
      "GRU = Pred: 0 Prob: 0.039121754467487335\n"
     ]
    }
   ],
   "source": [
    "audio_path = r\"C:\\Users\\winon\\Documents\\Bootcamp\\ai-spam-call-detection\\dataset\\sample_call2.mp3\"\n",
    "\n",
    "transcript = transcribe_audio(audio_path)\n",
    "print(\"Transcript:\", transcript)\n",
    "\n",
    "xgb_pred, xgb_prob = predict_xgb(transcript)\n",
    "\n",
    "gru_pred, gru_prob = predict_gru(transcript)\n",
    "\n",
    "print(\"\\n=== RESULT ===\")\n",
    "print(\"XGB = Pred:\", xgb_pred, \"Prob:\", xgb_prob)\n",
    "print(\"GRU = Pred:\", gru_pred, \"Prob:\", gru_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f0b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: Hi, this is Daniel from Amazon Customer Service. We have seen a recent order number AMZ0987 of iPhone 11 Pro on your account, which is billed on your card attached to your Amazon account. The amount charged is $1,499. We notice some suspicious activity on your account, so we have put a hold to this transaction. Please press 1 now, and to report please press 2. Thank you.\n",
      "\n",
      "=== RESULT ===\n",
      "XGB = Pred: 1 Prob: 0.9995266\n",
      "GRU = Pred: 0 Prob: 0.11535235494375229\n"
     ]
    }
   ],
   "source": [
    "audio_path = r\"C:\\Users\\winon\\Documents\\Bootcamp\\ai-spam-call-detection\\dataset\\sample_call.mp3\"\n",
    "\n",
    "transcript = transcribe_audio(audio_path)\n",
    "print(\"Transcript:\", transcript)\n",
    "\n",
    "xgb_pred, xgb_prob = predict_xgb(transcript)\n",
    "\n",
    "gru_pred, gru_prob = predict_gru(transcript)\n",
    "\n",
    "print(\"\\n=== RESULT ===\")\n",
    "print(\"XGB = Pred:\", xgb_pred, \"Prob:\", xgb_prob)\n",
    "print(\"GRU = Pred:\", gru_pred, \"Prob:\", gru_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "764206e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: Hello. Hi, Grandpa. How are you?\n",
      "\n",
      "=== RESULT ===\n",
      "XGB = Pred: 0 Prob: 0.028521826\n",
      "GRU = Pred: 0 Prob: 0.07341259717941284\n"
     ]
    }
   ],
   "source": [
    "audio_path = r\"C:\\Users\\winon\\Documents\\Bootcamp\\ai-spam-call-detection\\dataset\\sample_call3.wav\"\n",
    "\n",
    "transcript = transcribe_audio(audio_path)\n",
    "print(\"Transcript:\", transcript)\n",
    "\n",
    "xgb_pred, xgb_prob = predict_xgb(transcript)\n",
    "\n",
    "gru_pred, gru_prob = predict_gru(transcript)\n",
    "\n",
    "print(\"\\n=== RESULT ===\")\n",
    "print(\"XGB = Pred:\", xgb_pred, \"Prob:\", xgb_prob)\n",
    "print(\"GRU = Pred:\", gru_pred, \"Prob:\", gru_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e3be5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: Or would like to stop the disjoin? Please press one to start your claim. Otherwise, press two to speak with the billing department.\n",
      "\n",
      "=== RESULT ===\n",
      "XGB = Pred: 1 Prob: 0.98128635\n",
      "GRU = Pred: 1 Prob: 0.9555901288986206\n"
     ]
    }
   ],
   "source": [
    "audio_path = r\"C:\\Users\\winon\\Documents\\Bootcamp\\ai-spam-call-detection\\dataset\\sample_call4.wav\"\n",
    "\n",
    "transcript = transcribe_audio(audio_path)\n",
    "print(\"Transcript:\", transcript)\n",
    "\n",
    "xgb_pred, xgb_prob = predict_xgb(transcript)\n",
    "\n",
    "gru_pred, gru_prob = predict_gru(transcript)\n",
    "\n",
    "print(\"\\n=== RESULT ===\")\n",
    "print(\"XGB = Pred:\", xgb_pred, \"Prob:\", xgb_prob)\n",
    "print(\"GRU = Pred:\", gru_pred, \"Prob:\", gru_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "816a72d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: Hi, this is Emma with the Processing Center. I was giving you a quick call because I am reviewing your student loan profile, and as you know, there have been some pretty big changes to the federal student loan programs recently. When you have a moment, give me a call back. I would like to discuss your possible options with you while the programs are still available. It's urgent that you return my call prior to when payments resume. If you could please call me at 866-758-1276 to complete your application and finalize your enrollment as soon as possible. Again, that's 866-758-1276. Please have your reference number ready. Your reference number is SL367. I look forward to hearing from you soon, and I hope you have a great day.\n",
      "\n",
      "=== RESULT ===\n",
      "XGB = Pred: 1 Prob: 0.8566606\n",
      "GRU = Pred: 0 Prob: 0.22885000705718994\n"
     ]
    }
   ],
   "source": [
    "audio_path = r\"C:\\Users\\winon\\Documents\\Bootcamp\\ai-spam-call-detection\\dataset\\sample_call5.wav\"\n",
    "\n",
    "transcript = transcribe_audio(audio_path)\n",
    "print(\"Transcript:\", transcript)\n",
    "\n",
    "xgb_pred, xgb_prob = predict_xgb(transcript)\n",
    "\n",
    "gru_pred, gru_prob = predict_gru(transcript)\n",
    "\n",
    "print(\"\\n=== RESULT ===\")\n",
    "print(\"XGB = Pred:\", xgb_pred, \"Prob:\", xgb_prob)\n",
    "print(\"GRU = Pred:\", gru_pred, \"Prob:\", gru_prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
